{"cells":[{"cell_type":"markdown","metadata":{"id":"x46zeyPbkgaT"},"source":["Input necessary classes"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":693,"status":"ok","timestamp":1711261733984,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"VQtZSdjR4eur"},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import os"]},{"cell_type":"markdown","metadata":{"id":"dSyAWYuVkmM-"},"source":["Read input data\n"]},{"cell_type":"code","execution_count":188,"metadata":{"executionInfo":{"elapsed":670,"status":"ok","timestamp":1711261734645,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"k0PO8K73kpVR"},"outputs":[],"source":["input_data = pd.read_excel('Input.xlsx')\n"]},{"cell_type":"code","execution_count":189,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261734645,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"Lgl8We1EljQW","outputId":"c646113d-ee91-447f-98a5-17eedd3f0126"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"input_data\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"URL_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"blackassign0084\",\n          \"blackassign0054\",\n          \"blackassign0071\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\",\n          \"https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\",\n          \"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"input_data"},"text/html":["\n","  <div id=\"df-755c4540-9ec3-4bf4-a6e1-652d8c905b22\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL_ID</th>\n","      <th>URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>blackassign0001</td>\n","      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>blackassign0002</td>\n","      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>blackassign0003</td>\n","      <td>https://insights.blackcoffer.com/internet-dema...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>blackassign0004</td>\n","      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>blackassign0005</td>\n","      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>blackassign0096</td>\n","      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>blackassign0097</td>\n","      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>blackassign0098</td>\n","      <td>https://insights.blackcoffer.com/contribution-...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>blackassign0099</td>\n","      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>blackassign0100</td>\n","      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows Ã— 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-755c4540-9ec3-4bf4-a6e1-652d8c905b22')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-755c4540-9ec3-4bf4-a6e1-652d8c905b22 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-755c4540-9ec3-4bf4-a6e1-652d8c905b22');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-28458d8c-5f14-4e85-a606-0848d7b6253f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28458d8c-5f14-4e85-a606-0848d7b6253f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-28458d8c-5f14-4e85-a606-0848d7b6253f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_595915f5-294b-4887-b016-5eb8948896e9\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('input_data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_595915f5-294b-4887-b016-5eb8948896e9 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('input_data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["             URL_ID                                                URL\n","0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n","1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n","2   blackassign0003  https://insights.blackcoffer.com/internet-dema...\n","3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n","4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...\n","..              ...                                                ...\n","95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...\n","96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...\n","97  blackassign0098  https://insights.blackcoffer.com/contribution-...\n","98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...\n","99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...\n","\n","[100 rows x 2 columns]"]},"execution_count":189,"metadata":{},"output_type":"execute_result"}],"source":["input_data"]},{"cell_type":"markdown","metadata":{"id":"aAGhIvEZnLu2"},"source":["Function to extract article text from URL and save as text file\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":190,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1711261734646,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"2pKYyeH3oJPY"},"outputs":[],"source":["#Function to extract article text from URL and save as text file\n","\n","def extract_and_save_article(url, url_id):\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    # Extract article title\n","    title = soup.find('title').get_text()\n","    # Find the main content area based on specific attributes or structure\n","    main_content = soup.find('div', class_='td-post-content tagdiv-type')  # Assuming article content is within this class\n","    if not main_content:\n","        main_content = soup.find('div', class_='tdb-block-inner td-fix-index')  # If not found, try finding in this class\n","    if not main_content:\n","        main_content = soup.body  # If main content not found, use entire body\n","\n","    # Extract article text from main content\n","    article_text = \"\"\n","    list_items = main_content.find_all('li')\n","    if list_items:\n","        # If list items exist, include paragraphs and list items in extraction\n","        for element in main_content.find_all(['p', 'li']):\n","            if element.name == 'p':  # Check if current element is a paragraph\n","                article_text += element.get_text() + \"\\n\"\n","            elif element.name == 'li':  # Check if current element is a list item\n","                article_text += element.get_text() + \"\\n\"\n","    else:\n","        # If no list items, only include paragraphs in extraction\n","        for paragraph in main_content.find_all('p'):\n","            article_text += paragraph.get_text() + \"\\n\"\n","\n","\n","    # Create directory if not exists\n","    output_dir = \"Output Extract\"\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Save article text to a text file\n","    with open(os.path.join(output_dir, f\"{url_id}.txt\"), \"w\", encoding=\"utf-8\") as file:\n","        file.write(title + \"\\n\")\n","        file.write(article_text)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FJm3GkKgsQgv"},"source":[" Extract article text for each URL in the input data\n"]},{"cell_type":"code","execution_count":191,"metadata":{"executionInfo":{"elapsed":56391,"status":"ok","timestamp":1711261791026,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"UL0xU2k5sSkE"},"outputs":[],"source":["\n","# Extract article text for each URL in the input data\n","\n","for index, row in input_data.iterrows():\n","    extract_and_save_article(row['URL'], row['URL_ID'])"]},{"cell_type":"markdown","metadata":{"id":"76RohiVkBGdx"},"source":["\n","\n","#Data Analysis\n"]},{"cell_type":"markdown","metadata":{"id":"1jWv1ziECyIT"},"source":["Import Classes"]},{"cell_type":"code","execution_count":192,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1711261791027,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"6tdzvhEeBJBZ"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","import re\n","import string\n"]},{"cell_type":"code","execution_count":193,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1711261791028,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"xt8LExDMW2l7","outputId":"c1043a7c-ebce-4880-c4de-764b22c1e5ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":193,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')\n"]},{"cell_type":"markdown","metadata":{"id":"zwMlC9dcC9NC"},"source":[" Load stopwords\n"]},{"cell_type":"code","execution_count":194,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261791028,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"duCuaZiBC_wQ","outputId":"d2a6af65-4660-4d44-9889-32090ca45ab9"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))"]},{"cell_type":"markdown","metadata":{"id":"iCT9kdFNDVOX"},"source":["#1. Sentimental Analysis"]},{"cell_type":"markdown","metadata":{"id":"H4odw1ApK4z2"},"source":["Clean Stopwords"]},{"cell_type":"code","execution_count":195,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1711261791028,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"JaEhek4iK9a6"},"outputs":[],"source":["\n","def load_stopwords(stopwords_folder):\n","    stopwords = {}\n","    for filename in os.listdir(stopwords_folder):\n","        if filename.startswith(\"StopWords_\") and filename.endswith(\".txt\"):\n","            category = filename.split(\"_\")[1].split(\".\")[0]  # Extract category from filename\n","            with open(os.path.join(stopwords_folder, filename), \"r\", encoding=\"utf-8\",errors=\"ignore\") as file:\n","                stopwords[category] = set(file.read().splitlines())\n","    return stopwords\n","\n","def clean_text(text, stopwords):\n","    cleaned_text = \" \".join(word for word in text.split() if word.lower() not in stopwords)\n","    return cleaned_text\n","\n","def clean_all_files(input_dir, output_dir, stopwords_folder):\n","    # Create output directory if not exists\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Load all stop words files\n","    stopwords = load_stopwords(stopwords_folder)\n","\n","    # Iterate through each text file in the input directory\n","    for filename in os.listdir(input_dir):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(input_dir, filename)\n","            output_file_path = os.path.join(output_dir, filename)\n","\n","            # Read text from input file\n","            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","                text = file.read()\n","\n","            # Clean text by removing stop words for each category\n","            cleaned_text = text\n","            for category, words in stopwords.items():\n","                cleaned_text = clean_text(cleaned_text, words)\n","\n","            # Save cleaned text to output file\n","            with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n","                file.write(cleaned_text)\n"]},{"cell_type":"code","execution_count":196,"metadata":{"executionInfo":{"elapsed":2583,"status":"ok","timestamp":1711261793599,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"iaHN0mGRLB1v"},"outputs":[],"source":["# Specify input directory containing 100 text files\n","input_directory = \"Output Extract\"\n","\n","# Specify output directory to save cleaned text files\n","output_directory = \"Output Clean\"\n","\n","# Specify folder containing stop words files\n","stopwords_folder = \"StopWords\"\n","\n","# Clean all text files\n","clean_all_files(input_directory, output_directory, stopwords_folder)"]},{"cell_type":"markdown","metadata":{"id":"SeES697zEHJS"},"source":[" Load positive and negative words\n","\n"]},{"cell_type":"code","execution_count":197,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1711261793600,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"y86eNZzqTgrl"},"outputs":[],"source":["# Function to load words from file using different encodings\n","def load_words_from_file(filename):\n","    for encoding in encodings_to_try:\n","        try:\n","            with open(filename, 'r', encoding=encoding) as file:\n","                return [line.strip().lower() for line in file]\n","        except UnicodeDecodeError:\n","            continue\n","    # Raise an error if none of the encodings work\n","    raise UnicodeDecodeError(f\"Unable to decode file '{filename}' using any of the specified encodings: {encodings_to_try}\")"]},{"cell_type":"code","execution_count":198,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1711261793600,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"Kegsrt0nEKUA"},"outputs":[],"source":["positive_words = set()\n","negative_words = set()\n","\n","# Define a list of possible encodings to try\n","encodings_to_try = ['utf-8', 'latin-1']  # Add more encodings if needed\n","\n","\n","# Function to load words from file using different encodings\n","def load_words_from_file(filename):\n","    for encoding in encodings_to_try:\n","        try:\n","            with open(filename, 'r', encoding=encoding) as file:\n","                return [line.strip().lower() for line in file]\n","        except UnicodeDecodeError:\n","            continue\n","    # Raise an error if none of the encodings work\n","    raise UnicodeDecodeError(f\"Unable to decode file '{filename}' using any of the specified encodings: {encodings_to_try}\")\n","\n","positive_words = set(load_words_from_file(\"MasterDictionary/positive-words.txt\"))\n","negative_words = set(load_words_from_file(\"MasterDictionary/negative-words.txt\"))"]},{"cell_type":"code","execution_count":199,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1711261793600,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"QTYb-g5oDbX9"},"outputs":[],"source":["def calculate_derived_variables(text, positive_words, negative_words):\n","    # Tokenize the text into words\n","    words = word_tokenize(text)\n","\n","    # Initialize variables for positive and negative scores\n","    pos_score = 0\n","    neg_score = 0\n","\n","    # Count positive and negative words\n","    for word in words:\n","        if word.lower() in positive_words:\n","            pos_score += 1\n","        elif word.lower() in negative_words:\n","            neg_score += 1\n","\n","    # Calculate polarity score\n","    polarity_score = (pos_score - neg_score) / (pos_score + neg_score + 0.000001)\n","\n","    # Calculate subjectivity score\n","    total_words = len(words)\n","    subjectivity_score = (pos_score + neg_score) / (total_words + 0.000001)\n","\n","    return pos_score, neg_score, polarity_score, subjectivity_score"]},{"cell_type":"markdown","metadata":{"id":"Wwc14fWKdrUw"},"source":["#2.\tAnalysis of Readability"]},{"cell_type":"code","execution_count":200,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1711261793601,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"4X7Xy-xHdwuJ"},"outputs":[],"source":["# Function to calculate readability analysis variables\n","\n","def calculate_readability(text):\n","    # Tokenize the text into sentences\n","    sentences = sent_tokenize(text)\n","\n","    # Tokenize the text into words\n","    words = [word.lower() for word in word_tokenize(text) if word.isalnum()]\n","\n","    # Remove punctuation\n","    words = [word for word in words if word not in stop_words and word not in string.punctuation]\n","\n","    # Initialize variables for readability analysis\n","    total_words = len(words)\n","    total_sentences = len(sentences)\n","    complex_word_count = 0\n","\n","    # Calculate the average sentence length\n","    average_sentence_length = total_words / total_sentences\n","\n","    # Calculate the percentage of complex words\n","    for word in words:\n","        if syllable_count(word) > 2:  # Assuming words with more than 2 syllables are complex\n","            complex_word_count += 1\n","\n","    percentage_complex_words = (complex_word_count / total_words) * 100\n","\n","    # Calculate Fog Index\n","    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n","\n","    return average_sentence_length, percentage_complex_words, fog_index, complex_word_count\n","\n","# Function to count syllables in a word\n","def syllable_count(word):\n","    vowels = 'aeiouy'\n","    count = 0\n","    prev_char_is_vowel = False\n","    for char in word:\n","        char = char.lower()\n","        if char in vowels and not prev_char_is_vowel:\n","            count += 1\n","            prev_char_is_vowel = True\n","        elif char not in vowels:\n","            prev_char_is_vowel = False\n","    if len(word) > 2 and word.endswith('e') and not word.endswith('le'):\n","        count -= 1\n","    return max(count, 1)"]},{"cell_type":"markdown","metadata":{"id":"S5q6DvjSjZls"},"source":["#3. Average Number of Words Per Sentence"]},{"cell_type":"code","execution_count":201,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261793601,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"gZcGiEwUjdB1"},"outputs":[],"source":["# Function to calculate Average Number of Words Per Sentence variables\n","\n","def average_words_per_sentence(text):\n","    # Tokenize the text into sentences\n","    sentences = nltk.sent_tokenize(text)\n","\n","    # Count the total number of words\n","    words = nltk.word_tokenize(text)\n","    total_words = len(words)\n","\n","    # Count the total number of sentences\n","    total_sentences = len(sentences)\n","\n","    # Calculate the average number of words per sentence\n","    if total_sentences > 0:\n","        avg_words_per_sentence = total_words / total_sentences\n","    else:\n","        avg_words_per_sentence = 0\n","\n","    return avg_words_per_sentence"]},{"cell_type":"markdown","metadata":{"id":"a-YdqMUYqByk"},"source":["# 4. \tWord Count"]},{"cell_type":"code","execution_count":202,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261793602,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"wCnTStWbqDT7"},"outputs":[],"source":["#Function to calculate Word Count variables\n","def count_cleaned_words(text):\n","    # Tokenize the text into words\n","    words = nltk.word_tokenize(text)\n","\n","    # Remove punctuation\n","    words = [word for word in words if word not in string.punctuation]\n","\n","    # Count the cleaned words\n","    word_count = len(words)\n","\n","    return word_count"]},{"cell_type":"markdown","metadata":{"id":"FyvIl2p7rSor"},"source":["#5. Syllable Count Per Word"]},{"cell_type":"code","execution_count":203,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1711261793603,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"JBim_v8krVTs"},"outputs":[],"source":["# Function to Calculate Syllable Count Per Word variables\n","\n","def count_syllables_per_text(text):\n","    total_syllables = 0\n","    vowels = 'aeiouy'\n","\n","    # Tokenize the text into words\n","    words = [word.lower() for word in word_tokenize(text) if word.isalnum()]\n","\n","    # Remove punctuation\n","    words = [word for word in words if word not in stop_words and word not in string.punctuation]\n","\n","    # Count syllables for each word\n","    for word in words:\n","        count = 0\n","        prev_char_is_vowel = False\n","\n","        # Handle exceptions for words ending with \"es\" or \"ed\"\n","        if word.endswith('es') or word.endswith('ed'):\n","            total_syllables += 0\n","            continue\n","\n","        for char in word:\n","            char = char.lower()\n","            if char in vowels and not prev_char_is_vowel:\n","                count += 1\n","                prev_char_is_vowel = True\n","            elif char not in vowels:\n","                prev_char_is_vowel = False\n","\n","        # Apply additional rules or exceptions as needed\n","\n","        total_syllables += max(count, 1)  # Ensure minimum syllable count of 1\n","\n","    return total_syllables\n"]},{"cell_type":"markdown","metadata":{"id":"6BKbE0RJ1na8"},"source":["#6.\tPersonal Pronouns"]},{"cell_type":"code","execution_count":204,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261793604,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"lztbZ1IQ1ozS"},"outputs":[],"source":["# Function to Calculate Personal Pronouns variables\n","\n","def count_personal_pronouns(text):\n","    # Define the list of personal pronouns\n","    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n","\n","    # Compile the regex pattern to match the personal pronouns\n","    pattern = re.compile(r'\\b(?:' + '|'.join(personal_pronouns) + r')\\b', flags=re.IGNORECASE)\n","\n","    # Find all matches of personal pronouns in the text\n","    matches = re.findall(pattern, text)\n","\n","    # Count the total occurrences of personal pronouns\n","    personal_pronouns_count = len(matches)\n","\n","    return personal_pronouns_count\n"]},{"cell_type":"markdown","metadata":{"id":"gLMw5y543y_6"},"source":["#7. Average Word Length"]},{"cell_type":"code","execution_count":205,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1711261793605,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"d_kLY7za33n2"},"outputs":[],"source":["def calculate_average_word_length(text):\n","    # Tokenize the text into words\n","    words = text.split()\n","\n","    # Calculate the total number of characters in all words\n","    total_characters = sum(len(word) for word in words)\n","\n","    # Count the total number of words\n","    total_words = len(words)\n","\n","    # Calculate the average word length\n","    if total_words > 0:\n","        average_word_length = total_characters / total_words\n","    else:\n","        average_word_length = 0\n","\n","    return average_word_length\n"]},{"cell_type":"markdown","metadata":{"id":"R7E7jEZgeINB"},"source":["# Result"]},{"cell_type":"code","execution_count":206,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5158,"status":"ok","timestamp":1711261798747,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"otvPgqmrVyoz","outputId":"fb972e78-cbb2-4d9b-c518-f350f2858378"},"outputs":[{"name":"stdout","output_type":"stream","text":["             URL_ID  Positive Score  Negative Score  Polarity Score  \\\n","0   blackassign0001              33               6        0.692308   \n","1   blackassign0002              60              31        0.318681   \n","2   blackassign0003              38              24        0.225806   \n","3   blackassign0004              38              75       -0.327434   \n","4   blackassign0005              21               8        0.448276   \n","..              ...             ...             ...             ...   \n","95  blackassign0096              29              57       -0.325581   \n","96  blackassign0097              25              35       -0.166667   \n","97  blackassign0098               7               2        0.555555   \n","98  blackassign0099               0               0        0.000000   \n","99  blackassign0100               1               0        0.999999   \n","\n","    Subjectivity Score  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n","0             0.053793             7.466667                    28.035714   \n","1             0.087669            10.050633                    40.554156   \n","2             0.078780            10.946429                    54.323002   \n","3             0.146373            12.060000                    51.575456   \n","4             0.063736             9.179487                    36.871508   \n","..                 ...                  ...                          ...   \n","95            0.126657            11.604167                    42.549372   \n","96            0.102564            11.315789                    30.465116   \n","97            0.029221            10.863636                    37.656904   \n","98            0.000000             2.500000                    60.000000   \n","99            0.125000             2.500000                    20.000000   \n","\n","    FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n","0   14.200952                          9.666667                 157   \n","1   20.241916                         13.139241                 322   \n","2   26.107772                         14.053571                 333   \n","3   25.454182                         15.440000                 311   \n","4   18.420398                         11.666667                 132   \n","..        ...                               ...                 ...   \n","95  21.661415                         14.145833                 237   \n","96  16.712362                         15.394737                 131   \n","97  19.408216                         14.000000                  90   \n","98  25.000000                          4.000000                   3   \n","99   9.000000                          4.000000                   1   \n","\n","    WORD COUNT  SYLLABLE PER WORD  Personal Pronouns Count  \\\n","0          579           1.901554                        1   \n","1          837           2.048984                        2   \n","2          640           2.375000                        0   \n","3          622           2.434084                        0   \n","4          379           1.968338                        0   \n","..         ...                ...                      ...   \n","95         594           1.983165                        2   \n","96         478           1.648536                        2   \n","97         255           2.000000                        0   \n","98           6           1.666667                        0   \n","99           6           1.500000                        0   \n","\n","    Average Word Length  \n","0              6.746967  \n","1              7.700000  \n","2              8.522907  \n","3              8.332790  \n","4              7.730667  \n","..                  ...  \n","95             7.437819  \n","96             6.869281  \n","97             7.043651  \n","98             8.000000  \n","99             6.285714  \n","\n","[100 rows x 14 columns]\n"]}],"source":["results = []\n","\n","for filename in os.listdir(output_directory):\n","    if filename.endswith('.txt'):\n","        # Read the text from the file\n","        with open(os.path.join(output_directory, filename), 'r', encoding='utf-8') as file:\n","            text = file.read()\n","\n","        # Calculate derived variables\n","        pos_score, neg_score, polarity_score, subjectivity_score = calculate_derived_variables(text, positive_words, negative_words)\n","\n","        # Calculate readability analysis variables\n","        average_sentence_length, percentage_complex_words, fog_index, complex_word_count = calculate_readability(text)\n","\n","        # Calculate Average Number of Words Per Sentence variables\n","        avg_words_per_sentence = average_words_per_sentence(text)\n","\n","        # Calculate Word Count variables\n","        word_count = count_cleaned_words(text)\n","\n","        # Calculate the Syllable Count Per Word variable\n","        total_syllables = count_syllables_per_text(text)\n","        avg_syllables_per_word = total_syllables / word_count if word_count > 0 else 0\n","\n","        # Calculate Personal Pronouns Count variables\n","        pronoun_count = count_personal_pronouns(text)\n","\n","        # Calculate Word Count variables\n","        avg_word_length = calculate_average_word_length(text)\n","\n","        # Extract URL ID from filename\n","        url_id = os.path.splitext(filename)[0]\n","\n","        # Append results to the list\n","        results.append({\n","            \"URL_ID\": url_id,\n","            \"Positive Score\": pos_score,\n","            \"Negative Score\": neg_score,\n","            \"Polarity Score\": polarity_score,\n","            \"Subjectivity Score\": subjectivity_score,\n","            \"AVG SENTENCE LENGTH\": average_sentence_length,\n","            \"PERCENTAGE OF COMPLEX WORDS\": percentage_complex_words,\n","            \"FOG INDEX\": fog_index,\n","            \"AVG NUMBER OF WORDS PER SENTENCE\": avg_words_per_sentence,\n","            \"COMPLEX WORD COUNT\": complex_word_count,\n","            \"WORD COUNT\": word_count,\n","            \"SYLLABLE PER WORD\": avg_syllables_per_word,\n","            \"Personal Pronouns Count\": pronoun_count,\n","            \"Average Word Length\": avg_word_length\n","        })\n","\n","# Create DataFrame from results\n","output_df = pd.DataFrame(results)\n","# Sort the results based on the URL ID\n","output_df = output_df.sort_values(by=\"URL_ID\")\n","# Print the DataFrame\n","print(output_df)"]},{"cell_type":"code","execution_count":207,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1711261798748,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"YuM_Ioco9ai4"},"outputs":[],"source":["# Merge the two dataframes based on the URL ID column\n","merged_df = pd.merge(output_df, input_data[['URL_ID', 'URL']], on='URL_ID')\n","\n","# Reorganize the columns\n","merged_df = merged_df[['URL_ID', 'URL', 'Positive Score', 'Negative Score', 'Polarity Score',\n","                       'Subjectivity Score', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS',\n","                       'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT',\n","                       'WORD COUNT', 'SYLLABLE PER WORD', 'Personal Pronouns Count', 'Average Word Length']]\n"]},{"cell_type":"code","execution_count":208,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1711261798748,"user":{"displayName":"Narayanan Mannazhi","userId":"03335935085377380146"},"user_tz":-330},"id":"zbcKSIkbHkjy"},"outputs":[],"source":["\n","# Save the merged dataframe to a new Excel file\n","merged_df.to_excel(\"Output Data Structure.xlsx\", index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMiy9iAmVJPjKhoE/V+NjeB","mount_file_id":"1xuQ61rIi1Uq3OlHDhW36Xa0Kz9E1RhNV","provenance":[{"file_id":"1xS0X8o2NIRdrH7vA9xIMS7wHbpOM_k0x","timestamp":1711207064206}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
